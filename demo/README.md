## âš ï¸ Warning
Due to a busy schedule latelyğŸ˜¢, the following demo has not been verified yet.  I wrote it quickly based on logical reasoning to hopefully cover the common needs of many developers/researchersğŸ§‘â€ğŸ“. I will check it as soon as possible. If you encounter any problems, feel free to open an issue.

## ğŸ› ï¸ Installation
We need to install some package to launch the files in here.
```bash
# activate environment
conda activate Uni-Sign
# install other relevant dependencies
pip install rtmlib, onnxruntime-gpu, cuda-toolkit
```

## ğŸ¦´ Pose Extraction
```bash
# cd to root workspace
cd Uni-Sign
# pose extraction
# Note: Please specify the paths for {video_dir} and {pose_dir} before running command
# The {video_dir} directory contains multiple .mp4 files.
python ./demo/pose_extraction.py \
    --src_dir {video_dir} \
    --tgt_dir {pose_dir}
```

## âœˆï¸ Online Inference
```bash
# cd to root workspace
cd Uni-Sign
# online inference, we provide two mode here
# Note: Please specify the video path for {video_path} before running command
   
# Mode1: Pose-only setting
ckpt_path=out/stage3_finetuning/best_checkpoint.pth

python ./demo/online_inference.py \
   --online_video {video_path} \
   --finetune {ckpt_path}
   
# Mode2: RGB-pose setting
ckpt_path=out/stage3_finetuning/best_checkpoint.pth

python ./demo/online_inference.py \
   --online_video {video_path} \
   --finetune {ckpt_path} \
   --rgb_support
```
